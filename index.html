<!DOCTYPE html>
<html lang="en">

<head>
    <title>Object Detection with TensorFlow.js Benchmark</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Jason Mayes">

    <!-- Import the webpage's stylesheet -->
    <style>
        body {
            font-family: helvetica, arial, sans-serif;
            margin: 2em;
            color: #3D3D3D;
        }

        h1 {
            font-style: italic;
            color: #FF6F00;
        }

        h2 {
            clear: both;
        }

        em {
            font-weight: bold;
        }

        video {
            clear: both;
            display: block;
        }

        section {
            opacity: 1;
            transition: opacity 500ms ease-in-out;
        }

        header,
        footer {
            clear: both;
        }

        .removed {
            display: none;
        }

        .invisible {
            opacity: 0.2;
        }

        .note {
            font-style: italic;
            font-size: 130%;
        }

        .videoView,
        .classifyOnClick {
            position: relative;
            float: left;
            width: 100%;
            margin: 2% 1%;
            cursor: pointer;
        }

        .videoView p,
        .classifyOnClick p {
            position: absolute;
            padding: 5px;
            background-color: rgba(255, 111, 0, 0.85);
            color: #FFF;
            border: 1px dashed rgba(255, 255, 255, 0.7);
            z-index: 2;
            font-size: 12px;
            margin: 0;
        }

        .highlighter {
            background: rgba(0, 255, 0, 0.25);
            border: 1px dashed #fff;
            z-index: 1;
            position: absolute;
        }

        .classifyOnClick {
            z-index: 0;
        }

        .classifyOnClick img {
            width: 100%;
        }
    </style>
</head>

<body>
    <h1>Object Detection with TensorFlow.js Benchmark</h1>
    <p>
        This is a small benchmark to see how fast <a href="https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd">coco-ssd</a> runs on TensorFlow.js in the browser.
        Please upload your results to <a href="https://github.com/nonocam/poc-tfjs-demo">GitHub</a> or send me a message via <a href="https://twitter.com/_vsaw">Twitter</a>
    </p>
    <section id="loading">
        <h2>Loading...</h2>
    </section>
    <section id="demos" class="invisible">
        <div id="liveView" class="videoView">
            <button id="webcamButton">Enable Webcam</button>
            <span id="fps"></span> fps
            <video id="webcam" style="max-width: 100%;" autoplay playsinline></video>
        </div>
    </section>

    <!-- Import TensorFlow.js library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js" type="text/javascript"></script>

    <!-- Load the coco-ssd model to use to recognize things in images -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <!-- Webcam -->
    <script type="text/javascript" src="https://unpkg.com/webcam-easy/dist/webcam-easy.min.js"></script>

    <!-- Import the page's JavaScript to do some stuff -->
    <script>
        /********************************************************************
         * Demo created by Jason Mayes 2020.
         *
         * Got questions? Reach out to me on social:
         * Twitter: @jason_mayes
         * LinkedIn: https://www.linkedin.com/in/creativetech
         ********************************************************************/

        const demosSection = document.getElementById('demos');

        var model = undefined;

        // Before we can use COCO-SSD class we must wait for it to finish
        // loading. Machine Learning models can be large and take a moment to
        // get everything needed to run.
        cocoSsd.load().then(function (loadedModel) {
            model = loadedModel;
            // Show demo section now model is ready to use.
            demosSection.classList.remove('invisible');
            document.getElementById('loading').style = 'display: none;';
        });

        /********************************************************************
        // Demo 2: Continuously grab image from webcam stream and classify it.
        // Note: You must access the demo on https for this to work:
        // https://tensorflow-js-image-classification.glitch.me/
        ********************************************************************/

        const video = document.getElementById('webcam');
        const liveView = document.getElementById('liveView');

        // Check if webcam access is supported.
        function hasGetUserMedia() {
            return !!(navigator.mediaDevices &&
                navigator.mediaDevices.getUserMedia);
        }

        // Keep a reference of all the child elements we create
        // so we can remove them easilly on each render.
        var children = [];


        // If webcam supported, add event listener to button for when user
        // wants to activate it.
        if (hasGetUserMedia()) {
            const enableWebcamButton = document.getElementById('webcamButton');
            enableWebcamButton.addEventListener('click', enableCam);
        } else {
            console.warn('getUserMedia() is not supported by your browser');
        }


        // Enable the live webcam view and start classification.
        function enableCam(event) {
            if (!model) {
                console.log('Wait! Model not loaded yet.')
                return;
            }

            // Hide the button.
            // event.target.classList.add('removed');

            // getUsermedia parameters.
            const constraints = {
                video: {
                    facingMode: "environment",
                    width: 1280,
                    height: 720,
                }
            };

            // Activate the webcam stream.
            navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                video.srcObject = stream;
                video.addEventListener('loadeddata', predictWebcam);
            });
        }

        frame = 0;
        setInterval(() => {
            document.getElementById("fps").innerText = frame;
            frame = 0;
        }, 1000);

        // Prediction loop!
        function predictWebcam() {
            // console.debug(video);
            const scale = video.clientWidth / 1280.0;

            // Now let's start classifying the stream.
            model.detect(video).then(function (predictions) {
                frame++;

                // Remove any highlighting we did previous frame.
                for (let i = 0; i < children.length; i++) {
                    liveView.removeChild(children[i]);
                }
                children.splice(0);

                // Now lets loop through predictions and draw them to the live view if
                // they have a high confidence score.
                for (let n = 0; n < predictions.length; n++) {
                    // If we are over 66% sure we are sure we classified it right, draw it!
                    if (predictions[n].score > 0.66) {
                        const p = document.createElement('p');
                        p.innerText = predictions[n].class + ' - with '
                            + Math.round(parseFloat(predictions[n].score) * 100)
                            + '% confidence.';
                        // Draw in top left of bounding box outline.
                        p.style = 'left: ' + predictions[n].bbox[0] * scale + 'px;' +
                            'top: ' + predictions[n].bbox[1] * scale + 'px;' +
                            'width: ' + (predictions[n].bbox[2] * scale - 10) + 'px;';

                        // Draw the actual bounding box.
                        const highlighter = document.createElement('div');
                        highlighter.setAttribute('class', 'highlighter');
                        highlighter.style = 'left: ' + predictions[n].bbox[0] * scale + 'px;'
                            + 'top: ' + predictions[n].bbox[1] * scale + 'px;'
                            + 'width: '+ predictions[n].bbox[2] * scale + 'px;'
                            + 'height: ' + predictions[n].bbox[3] * scale + 'px;';

                        liveView.appendChild(highlighter);
                        liveView.appendChild(p);

                        // Store drawn objects in memory so we can delete them next time around.
                        children.push(highlighter);
                        children.push(p);
                    }
                }

                // Call this function again to keep predicting when the browser is ready.
                window.requestAnimationFrame(predictWebcam);
            });
        }
    </script>
</body>

</html>
